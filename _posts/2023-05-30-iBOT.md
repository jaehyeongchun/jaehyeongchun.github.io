---
title:  "[Computer Vision] Self-Supervised Learning 톺아보기 ; iBOT"
excerpt: "ICLR 2022 DINO : iBOT 🤖: Image BERT Pre-Training with Online Tokenizer (ICLR 2022)"
comments: true
categories:
  - deeplearning
tags:
  - [Blog, Deeplearning, Self-Supervised Learning, ComputerVision, SSL, VICReg]

use_math: true
date: 2023-05-30
last_modified_at: 2023-05-30    

published: True

---

![image](https://github.com/jaehyeongchun/jaehyeongchun.github.io/assets/31461053/bb3dea3d-f756-483f-9c39-4c884f9ec323)

ICLR 2022에서 발표된 iBOT 🤖: Image BERT Pre-Training with Online Tokenizer입니다.

Language model training에 있어 Masked Language Modeling(MLM)은 성공적인 paradigm으로 자리잡았습니다.

대표적으로 BERT가 그러했죠.

이러한 성공 기반에는 lingual tokenizer (ex. WordPiece, BPE, Unigram)를 활용해 input을 semantically meaningful token으로 만들어주는 것이 중요했습니다.

하지만 Visual semantics는 ligual semantics과 달리 image의 연속적인 특성으로 인해 쉽게 뽑아내기가 어렵습니다.

이를 해결하기 위해 BEIT : Pre-Training of Image Transformer에서는 DALL-E의 pre-trained VAE를 visual tokenizer로 활용했으나
이로 인해 multi-stage training pipeline이 불가피했고 또한 tokenizer가 high-level semantics을 잡아내는데 어려움을 보였습니다.

그렇기에 이 논문에서 저자는 Vision transformer를 잘 학습하기 위해 Online tokenizer와 Knowlege distillation을 통해
새로운 Masked Image Modeling (MIM) framework를 제시하였습니다. 

아래의 유튜브 동영상으로 논문에 대한 설명을 진행하였으니 한번 봐주시면 감사하겠습니다.

<iframe width="873" height="491" src="https://www.youtube.com/embed/eSlWQin30xY?list=PLyP9gclj-bv6Nh5Xp-rUMMiD8kI0kW_E8" title="[SSL] 논문 리뷰 : iBOT 🤖: Image BERT Pre-Training with Online Tokenizer (ICLR 2022)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>  